{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+GjW/ooRANSbH6uxp7LvG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "# Loading the dataset\n",
        "data = pd.read_csv(\"creditcard.csv\")\n",
        "\n",
        "# Standardize 'Time' and 'Amount' columns\n",
        "scaler = StandardScaler()\n",
        "data['scaled_time'] = scaler.fit_transform(data['Time'].values.reshape(-1, 1))\n",
        "data['scaled_amount'] = scaler.fit_transform(data['Amount'].values.reshape(-1, 1))\n",
        "\n",
        "# Drop the original 'Time' and 'Amount' columns\n",
        "data = data.drop(['Time', 'Amount'], axis=1)\n",
        "\n",
        "# Spliting data into features and labels\n",
        "X = data.drop('Class', axis=1)\n",
        "y = data['Class']\n",
        "\n",
        "# Spliting the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Defining the autoencoder architecture\n",
        "def create_autoencoder(input_dim):\n",
        "    input_layer = Input(shape=(input_dim,))\n",
        "    \n",
        "    # Encoder\n",
        "    encoded = Dense(64, activation='relu')(input_layer)\n",
        "    encoded = Dense(32, activation='relu')(encoded)\n",
        "    \n",
        "    # Decoder\n",
        "    decoded = Dense(32, activation='relu')(encoded)\n",
        "    decoded = Dense(64, activation='relu')(decoded)\n",
        "    decoded = Dense(input_dim, activation='linear')(decoded)\n",
        "    \n",
        "    autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
        "    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "    \n",
        "    return autoencoder\n",
        "\n",
        "# Filtering out the normal transactions from the training set\n",
        "normal_train = X_train[y_train == 0]\n",
        "\n",
        "# Training the autoencoder\n",
        "autoencoder = create_autoencoder(normal_train.shape[1])\n",
        "autoencoder.fit(normal_train, normal_train, epochs=50, batch_size=256, validation_split=0.2, shuffle=True)\n",
        "\n",
        "# Predicting and calculate mean squared error for the test set\n",
        "y_pred = autoencoder.predict(X_test)\n",
        "mse = np.mean(np.power(X_test - y_pred, 2), axis=1)\n",
        "\n",
        "# Determining the threshold for anomaly detection\n",
        "normal_mse = mse[y_test == 0]\n",
        "threshold = np.quantile(normal_mse, 0.995)\n",
        "\n",
        "# Classifying transactions based on the threshold\n",
        "y_pred = (mse > threshold).astype(int)\n",
        "\n",
        "# Evaluating the model performance\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Saving the trained model\n",
        "autoencoder.save(\"fraud_detection_autoencoder.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7PDSt6eqmQu",
        "outputId": "c126a274-9283-4eec-ed7f-c2a48afd6728"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "711/711 [==============================] - 4s 4ms/step - loss: 0.2398 - val_loss: 0.0637\n",
            "Epoch 2/50\n",
            "711/711 [==============================] - 4s 5ms/step - loss: 0.0424 - val_loss: 0.0239\n",
            "Epoch 3/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0215 - val_loss: 0.0144\n",
            "Epoch 4/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0130 - val_loss: 0.0070\n",
            "Epoch 5/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0069 - val_loss: 0.0050\n",
            "Epoch 6/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0048 - val_loss: 0.0041\n",
            "Epoch 7/50\n",
            "711/711 [==============================] - 3s 5ms/step - loss: 0.0044 - val_loss: 0.0054\n",
            "Epoch 8/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0032 - val_loss: 0.0054\n",
            "Epoch 9/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0029 - val_loss: 0.0020\n",
            "Epoch 10/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0025 - val_loss: 0.0055\n",
            "Epoch 11/50\n",
            "711/711 [==============================] - 4s 5ms/step - loss: 0.0024 - val_loss: 0.0011\n",
            "Epoch 12/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0036 - val_loss: 0.0011\n",
            "Epoch 13/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 14/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0015 - val_loss: 8.2701e-04\n",
            "Epoch 15/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0016 - val_loss: 8.8819e-04\n",
            "Epoch 16/50\n",
            "711/711 [==============================] - 3s 5ms/step - loss: 0.0012 - val_loss: 7.7871e-04\n",
            "Epoch 17/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 18/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0018 - val_loss: 0.0054\n",
            "Epoch 19/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0020 - val_loss: 0.0017\n",
            "Epoch 20/50\n",
            "711/711 [==============================] - 4s 5ms/step - loss: 0.0010 - val_loss: 0.0035\n",
            "Epoch 21/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 9.1860e-04 - val_loss: 0.0016\n",
            "Epoch 22/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0012 - val_loss: 0.0015\n",
            "Epoch 23/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 9.7099e-04 - val_loss: 0.0036\n",
            "Epoch 24/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0013 - val_loss: 5.4767e-04\n",
            "Epoch 25/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0015 - val_loss: 5.3142e-04\n",
            "Epoch 26/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 8.6568e-04 - val_loss: 8.5344e-04\n",
            "Epoch 27/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0012 - val_loss: 0.0043\n",
            "Epoch 28/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 29/50\n",
            "711/711 [==============================] - 4s 5ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 30/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 9.8621e-04 - val_loss: 7.9366e-04\n",
            "Epoch 31/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 7.1177e-04 - val_loss: 5.4915e-04\n",
            "Epoch 32/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0010 - val_loss: 6.2523e-04\n",
            "Epoch 33/50\n",
            "711/711 [==============================] - 3s 5ms/step - loss: 7.3173e-04 - val_loss: 0.0177\n",
            "Epoch 34/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0012 - val_loss: 0.0021\n",
            "Epoch 35/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 9.9760e-04 - val_loss: 0.0103\n",
            "Epoch 36/50\n",
            "711/711 [==============================] - 2s 3ms/step - loss: 0.0010 - val_loss: 5.1965e-04\n",
            "Epoch 37/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 8.1537e-04 - val_loss: 3.9912e-04\n",
            "Epoch 38/50\n",
            "711/711 [==============================] - 4s 5ms/step - loss: 0.0014 - val_loss: 9.4120e-04\n",
            "Epoch 39/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 6.5339e-04 - val_loss: 5.6263e-04\n",
            "Epoch 40/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0017 - val_loss: 3.7920e-04\n",
            "Epoch 41/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 6.2296e-04 - val_loss: 7.1415e-04\n",
            "Epoch 42/50\n",
            "711/711 [==============================] - 3s 5ms/step - loss: 0.0011 - val_loss: 0.0013\n",
            "Epoch 43/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 6.1415e-04 - val_loss: 0.0013\n",
            "Epoch 44/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0016 - val_loss: 0.0011\n",
            "Epoch 45/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 9.0280e-04 - val_loss: 3.1934e-04\n",
            "Epoch 46/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 8.6134e-04 - val_loss: 3.7836e-04\n",
            "Epoch 47/50\n",
            "711/711 [==============================] - 4s 5ms/step - loss: 0.0013 - val_loss: 4.0039e-04\n",
            "Epoch 48/50\n",
            "711/711 [==============================] - 2s 3ms/step - loss: 6.2347e-04 - val_loss: 4.6783e-04\n",
            "Epoch 49/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 0.0011 - val_loss: 3.6023e-04\n",
            "Epoch 50/50\n",
            "711/711 [==============================] - 3s 4ms/step - loss: 9.1691e-04 - val_loss: 5.2205e-04\n",
            "1781/1781 [==============================] - 3s 2ms/step\n",
            "[[56579   285]\n",
            " [   17    81]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     56864\n",
            "           1       0.22      0.83      0.35        98\n",
            "\n",
            "    accuracy                           0.99     56962\n",
            "   macro avg       0.61      0.91      0.67     56962\n",
            "weighted avg       1.00      0.99      1.00     56962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following the evaluation of our anomaly detection model, we found that it is successful in identifying a majority of fraudulent transactions. \n",
        "\n",
        "# **The key takeaways are as follows:**\n",
        "\n",
        " - The model has an overall accuracy of 99%. However, due to the imbalanced \n",
        "nature of the dataset, accuracy is not the most suitable metric. Instead, we should focus on precision, recall, and F1-score for the minority class (fraudulent transactions).\n",
        "\n",
        " - The precision of our model is 0.22. This means that out of all transactions classified as fraudulent, only 22% are actually fraudulent. As a result, a significant number of normal transactions are misclassified as fraudulent, leading to potential false alarms.\n",
        "\n",
        " - The recall of our model is 0.83. This means that our model is able to correctly identify 83% of actual fraudulent transactions. A high recall is essential for a fraud detection system to capture as many fraudulent transactions as possible.\n",
        "\n",
        " - The F1-score, which is the harmonic mean of precision and recall, is 0.35. It is important to balance both precision and recall in order to minimize the number of false alarms while also detecting a high percentage of fraudulent transactions.\n",
        "\n",
        " - To improve the model's performance, we can consider experimenting with different neural network architectures or hyperparameters for the autoencoder. Additionally, addressing the class imbalance problem using techniques like oversampling, undersampling, or SMOTE may yield better results. Finally, comparing the performance of our model with other anomaly detection algorithms such as Isolation Forest or One-Class SVM can help us identify the most suitable approach for our fraud detection system."
      ],
      "metadata": {
        "id": "q_b4EfpN1EOw"
      }
    }
  ]
}